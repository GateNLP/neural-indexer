"""Script to automatically generate the embedder's docker-compose override files."""

import argparse
import os
import tempfile

import flow
import jina
import yaml
from dotenv import load_dotenv

parser = argparse.ArgumentParser(description="Generate Jina docker-compose file.")
parser.add_argument("compose_name", help="Name of the compose file to output")
parser.add_argument(
    "--gpu",
    "-g",
    help="Use GPUs for inference instead of CPU",
    default=False,
    action="store_true",
)
parser.add_argument(
    "--replicas",
    "-r",
    help="The number of embedder replicas to use",
    default=1,
    type=int,
)
parser.add_argument(
    "--network-name", "-n", help="Docker network name", default="default"
)
parser.add_argument(
    "--is-system",
    "-s",
    help="This profile is provided by the system, not the enduser.",
    action="store_true",
    default=False,
)

args = parser.parse_args()
args_sorted = sorted(vars(args).items(), key=lambda a: a[0])

load_dotenv()

if args.gpu:
    embedder_additional_uses_with = {"device": "cuda"}
    # ${EXECUTOR_GPU} will be resolved by Docker Compose
    embedder_additional_args = {"gpus": "device=${EXECUTOR_GPU}"}
    executor_suffix = "-gpu"
else:
    embedder_additional_uses_with = {}
    embedder_additional_args = {}
    executor_suffix = ""

f = flow.generate_flow(
    executor_suffix,
    embedder_additional_uses_with,
    args.replicas,
    embedder_additional_args,
)


# This is not a docker-compose file of honour
warning = [
    "DO NOT MODIFY - AUTOMATICALLY GENERATED FILE",
    "",
    "Generated by `compose_generator.py` with args:",
    *[" --{} {}\\".format(*arg) for arg in args_sorted],
]
# Remove the backslash from last arg
warning[-1] = warning[-1].removesuffix("\\")

compose_filename = "{}.yml".format(args.compose_name)

# Jina's .to_docker_compose_yaml is impolite and insists on outputting to a file...
# so we'll output to the system temp directory
temp_path = os.path.join(tempfile.gettempdir(), compose_filename)
f.to_docker_compose_yaml(output_path=temp_path, network_name=args.network_name)

# and open a new file to write our output to
final_path = os.path.join(
    os.path.dirname(__file__),
    "profiles" if args.is_system else "profiles/user",
    compose_filename,
)

with open(temp_path, "r") as in_f, open(final_path, "w") as out_f:
    original_compose = yaml.safe_load(in_f)

    # Since this file is going to be an override, we only need the services
    # and a definition for the huggingface cache volume
    compose = {
        "services": original_compose["services"],
        "volumes": {"huggingface": {"driver": "local"}},
    }

    # Adjust Gateway Version
    image = compose["services"]["gateway"]["image"]
    image = image.replace("master", jina.__version__)
    compose["services"]["gateway"]["image"] = image

    # Create a list of Prometheus endpoints to watch
    service_monitoring_hosts = []
    for service_name, service in compose["services"].items():
        # Find monitoring ports from expose
        # Typically 9090 then 9091,9092,... for executors
        monitoring_port = list(
            filter(lambda p: 9000 <= int(p) <= 9999, service["expose"])
        )

        assert (
            len(monitoring_port) == 1
        ), "Service {} has does not have exactly one possible monitoring port: {}".format(
            service_name, ",".join(monitoring_port)
        )
        monitoring_port = monitoring_port[0]

        service_monitoring_hosts.append(
            "http://{}:{}".format(service_name, monitoring_port)
        )

        # Don't forward the monitoring port
        compose["services"][service_name]["ports"].remove(
            "{0}:{0}".format(monitoring_port)
        )
        # Remove service ports if now empty
        if len(compose["services"][service_name]["ports"]) == 0:
            del compose["services"][service_name]["ports"]

        if "embedder" in service_name:
            # Change healthcheck to be more realistic
            compose["services"][service_name]["healthcheck"]["interval"] = "10s"
            compose["services"][service_name]["healthcheck"]["retries"] = 60

            # Patch Jina's incorrect GPU output
            if args.gpu:
                gpu_info = (compose["services"][service_name]["deploy"]
                        ["resources"]["reservations"]["devices"][0])  # fmt: skip

                if "count" in gpu_info:
                    del gpu_info["count"]
                    # ${EXECUTOR_GPU} will be resolved by Docker Compose
                    gpu_info["device_ids"] = ["${EXECUTOR_GPU}"]
                    (compose["services"][service_name]["deploy"]
                        ["resources"]["reservations"]["devices"][0]) = gpu_info  # fmt: skip
                else:
                    print(
                        "Notice: Couldn't patch Jina GPU output, may have been fixed upstream."
                    )

    # Add Jina containers to logstashembed's dependencies
    compose["services"]["logstashembed"] = {
        "depends_on": {
            service: {"condition": "service_healthy"} for service in compose["services"]
        }
    }

    # Tell metricbeat the hosts of the Jina containers
    compose["services"]["metricbeat"] = {
        "environment": ["JINA_HOSTS=[{}]".format(", ".join(service_monitoring_hosts))]
    }

    # And now output our new compose file with warning
    guard = "#" + ("=" * (len(max(warning, key=len)) + 2)) + "\n"
    out_f.write(guard)
    out_f.write("".join("# {}\n".format(line) for line in warning))
    out_f.write(guard + "\n\n")
    yaml.dump(compose, out_f)
