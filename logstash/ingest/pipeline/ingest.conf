input {
    file {
        check_archive_validity => true
        path => [
            "/ingest/**/*.json.gz",
            "/ingest/**/*.jsonl.gz",
            "/ingest/**/*.json",
            "/ingest/**/*.jsonl"
        ]
        mode => "read"
        sincedb_clean_after => "365 d"
        file_completed_action => "log_and_delete"
        file_completed_log_path => "/usr/share/logstash/data/completed.log"
    }
}

filter {
    json {
        source => "message"
    }

    mutate {
        rename => {
            "@timestamp" => "processed_by_logstash_at"
        }
    }

    mutate {
        remove_field => ["message", "event", "host", "@version"]
    }

    clone {
        clones => ["for_queue"]
    }

    if "for_queue" in [tags] {
        prune {
            whitelist_names => ["doc_id", "processed_by_logstash_at", "text", "^tags$"]
        }
    }
}

output {
    if "for_queue" in [tags] {
        rabbitmq {
            host => ["${RABBITMQ_HOSTS}"]
            user => "${RABBITMQ_USERNAME}"
            password => "${RABBITMQ_PASSWORD}"
            key => "to_embed"
            exchange => ""
            exchange_type => "direct"
        }
    } else {
        elasticsearch {
            hosts => "${ELASTICSEARCH_HOSTS}"
            cacert => '/usr/share/logstash/certs/ca/ca.crt'
            user => "${ELASTICSEARCH_USERNAME}"
            password => "${ELASTICSEARCH_PASSWORD}"

            document_id => "%{[doc_id]}"
            index => "${ELASTIC_INDEX}"
            action => "create"
        }
    }
}
